{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline for Extracting Keywords from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "#import numpy as np\n",
    "import pickle \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6623, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "path = \"/Users/ethanvirtudazo/Desktop/DS105_Dataset/6622_jobs.xls\"\n",
    "df_import = pd.read_excel(path)\n",
    "\n",
    "df_import.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA WRANGLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>details</th>\n",
       "      <th>deadline</th>\n",
       "      <th>opport_type</th>\n",
       "      <th>commence_date</th>\n",
       "      <th>contract_type</th>\n",
       "      <th>location</th>\n",
       "      <th>Renumeration</th>\n",
       "      <th>company</th>\n",
       "      <th>links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Rothschild &amp; Co - Private Equity Long-Term Int...</td>\n",
       "      <td>This London-based 6-month internship is an exc...</td>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>Internship</td>\n",
       "      <td>2023-07-01 00:00:00</td>\n",
       "      <td>Temporary</td>\n",
       "      <td>London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rothschild &amp; Co</td>\n",
       "      <td>https://careers.lse.ac.uk//students/jobs/detai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2023 HSBC Global Graduate Programme (Hong Kong...</td>\n",
       "      <td>You’re excited about starting your career and ...</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>Graduate employment</td>\n",
       "      <td>2023-07-03 00:00:00</td>\n",
       "      <td>Temporary</td>\n",
       "      <td>Hong KongSingapore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HSBC (HSBC) - Hong Kong</td>\n",
       "      <td>https://careers.lse.ac.uk//students/jobs/detai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0  Rothschild & Co - Private Equity Long-Term Int...   \n",
       "1           1  2023 HSBC Global Graduate Programme (Hong Kong...   \n",
       "\n",
       "                                             details   deadline  \\\n",
       "0  This London-based 6-month internship is an exc... 2023-04-30   \n",
       "1  You’re excited about starting your career and ... 2023-01-06   \n",
       "\n",
       "           opport_type        commence_date contract_type            location  \\\n",
       "0           Internship  2023-07-01 00:00:00     Temporary              London   \n",
       "1  Graduate employment  2023-07-03 00:00:00     Temporary  Hong KongSingapore   \n",
       "\n",
       "  Renumeration                  company  \\\n",
       "0          NaN          Rothschild & Co   \n",
       "1          NaN  HSBC (HSBC) - Hong Kong   \n",
       "\n",
       "                                               links  \n",
       "0  https://careers.lse.ac.uk//students/jobs/detai...  \n",
       "1  https://careers.lse.ac.uk//students/jobs/detai...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_import.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>details</th>\n",
       "      <th>deadline</th>\n",
       "      <th>opport_type</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rothschild &amp; Co - Private Equity Long-Term Int...</td>\n",
       "      <td>This London-based 6-month internship is an exc...</td>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>Internship</td>\n",
       "      <td>London</td>\n",
       "      <td>Rothschild &amp; Co</td>\n",
       "      <td>https://careers.lse.ac.uk//students/jobs/detai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023 HSBC Global Graduate Programme (Hong Kong...</td>\n",
       "      <td>You’re excited about starting your career and ...</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>Graduate employment</td>\n",
       "      <td>Hong KongSingapore</td>\n",
       "      <td>HSBC (HSBC) - Hong Kong</td>\n",
       "      <td>https://careers.lse.ac.uk//students/jobs/detai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023 HSBC Global Internship Programme (Hong Ko...</td>\n",
       "      <td>You’re excited about starting your career and ...</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Hong KongSingapore</td>\n",
       "      <td>HSBC (HSBC) - Hong Kong</td>\n",
       "      <td>https://careers.lse.ac.uk//students/jobs/detai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Graduate Training Scheme, Capital Markets</td>\n",
       "      <td>Graduate Training Scheme – LondonGreySpark Par...</td>\n",
       "      <td>2022-12-17</td>\n",
       "      <td>Graduate employment</td>\n",
       "      <td>London</td>\n",
       "      <td>GreySpark Partners Ltd</td>\n",
       "      <td>https://careers.lse.ac.uk//students/jobs/detai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6-Months Internship – Sell-side Tech M&amp;A</td>\n",
       "      <td>At IPTP, we understand software from decades o...</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>Internship</td>\n",
       "      <td>France</td>\n",
       "      <td>Inflexion Points Technology Partners (IPTP)</td>\n",
       "      <td>https://careers.lse.ac.uk//students/jobs/detai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Rothschild & Co - Private Equity Long-Term Int...   \n",
       "1  2023 HSBC Global Graduate Programme (Hong Kong...   \n",
       "2  2023 HSBC Global Internship Programme (Hong Ko...   \n",
       "3         Graduate Training Scheme, Capital Markets    \n",
       "4           6-Months Internship – Sell-side Tech M&A   \n",
       "\n",
       "                                             details   deadline  \\\n",
       "0  This London-based 6-month internship is an exc... 2023-04-30   \n",
       "1  You’re excited about starting your career and ... 2023-01-06   \n",
       "2  You’re excited about starting your career and ... 2023-01-06   \n",
       "3  Graduate Training Scheme – LondonGreySpark Par... 2022-12-17   \n",
       "4  At IPTP, we understand software from decades o... 2022-12-31   \n",
       "\n",
       "           opport_type            location  \\\n",
       "0           Internship              London   \n",
       "1  Graduate employment  Hong KongSingapore   \n",
       "2           Internship  Hong KongSingapore   \n",
       "3  Graduate employment              London   \n",
       "4           Internship              France   \n",
       "\n",
       "                                       company  \\\n",
       "0                              Rothschild & Co   \n",
       "1                      HSBC (HSBC) - Hong Kong   \n",
       "2                      HSBC (HSBC) - Hong Kong   \n",
       "3                       GreySpark Partners Ltd   \n",
       "4  Inflexion Points Technology Partners (IPTP)   \n",
       "\n",
       "                                               links  \n",
       "0  https://careers.lse.ac.uk//students/jobs/detai...  \n",
       "1  https://careers.lse.ac.uk//students/jobs/detai...  \n",
       "2  https://careers.lse.ac.uk//students/jobs/detai...  \n",
       "3  https://careers.lse.ac.uk//students/jobs/detai...  \n",
       "4  https://careers.lse.ac.uk//students/jobs/detai...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df_import.iloc[:, 1:5]\n",
    "\n",
    "df2 = df_import.iloc[:, [7,9,10]]\n",
    "\n",
    "pdList = [df1,df2]\n",
    "df = pd.concat(pdList,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title                  object\n",
      "details                object\n",
      "deadline       datetime64[ns]\n",
      "opport_type            object\n",
      "location               object\n",
      "company                object\n",
      "links                  object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df.shape\n",
    "\n",
    "types = df.dtypes\n",
    "print(types)\n",
    "\n",
    "df_title = df.iloc[:,0]\n",
    "df_text = df.iloc[:, [1]]\n",
    "\n",
    "df_dline = df.iloc[:, [2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This London-based 6-month internship is an exc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You’re excited about starting your career and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You’re excited about starting your career and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Graduate Training Scheme – LondonGreySpark Par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>At IPTP, we understand software from decades o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             details\n",
       "0  This London-based 6-month internship is an exc...\n",
       "1  You’re excited about starting your career and ...\n",
       "2  You’re excited about starting your career and ...\n",
       "3  Graduate Training Scheme – LondonGreySpark Par...\n",
       "4  At IPTP, we understand software from decades o..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deadline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    deadline\n",
       "0 2023-04-30\n",
       "1 2023-01-06\n",
       "2 2023-01-06\n",
       "3 2022-12-17\n",
       "4 2022-12-31"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6623"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIPELINE PART 1: NLP() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6623"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6620"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convering the column of texts into a list of text\n",
    "lst_lst = df_text.values.tolist()\n",
    "\n",
    "# storing the data type of every element in the list of texts (which contains all of the job details)\n",
    "# we expect the text data to be a 'str' object\n",
    "# non_str_index tells us which indexes include non-string values and therefore should be removed\n",
    "non_str_index = [i for i, sublst in enumerate(lst_lst) if any(not isinstance(val, str) for val in sublst)]\n",
    "non_str_index\n",
    "\n",
    "df_text_filtered = df_text.drop(non_str_index, axis=0, inplace=False) \n",
    "len(df_text_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_filtered_1 = df_text_filtered[0:1000]\n",
    "df_text_filtered_2 = df_text_filtered[1000:2000]\n",
    "df_text_filtered_3 = df_text_filtered[2000:3000]\n",
    "df_text_filtered_4 = df_text_filtered[3000:4000]\n",
    "df_text_filtered_5 = df_text_filtered[4000:5000]\n",
    "df_text_filtered_6 = df_text_filtered[5000:6000]\n",
    "df_text_filtered_7 = df_text_filtered[6000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_1 = df_text_filtered_1['details'].apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(docs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_2 = df_text_filtered_2['details'].apply(nlp)\n",
    "len(docs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_3 = df_text_filtered_3['details'].apply(nlp)\n",
    "len(docs_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_4 = df_text_filtered_4['details'].apply(nlp)\n",
    "len(docs_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_5 = df_text_filtered_5['details'].apply(nlp)\n",
    "len(docs_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_6 = df_text_filtered_6['details'].apply(nlp)\n",
    "len(docs_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "620"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_7 = df_text_filtered_7['details'].apply(nlp)\n",
    "len(docs_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6620,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_all = pd.concat([docs_1,docs_2,docs_3,docs_4,docs_5,docs_6,docs_7],\n",
    "ignore_index = True,\n",
    "sort = False)\n",
    "\n",
    "docs_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6620"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    (This, London, -, based, 6, -, month, internsh...\n",
       "1    (You, ’re, excited, about, starting, your, car...\n",
       "2    (You, ’re, excited, about, starting, your, car...\n",
       "3    (Graduate, Training, Scheme, –, LondonGreySpar...\n",
       "4    (At, IPTP, ,, we, understand, software, from, ...\n",
       "Name: details, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional!\n",
    "\n",
    "# use this to store the list of documents locally (running nlp() again takes time)\n",
    "\n",
    "#with open(\"all_spacy_docs.pickle\", \"wb\") as f:\n",
    "#    pickle.dump(all_docs, f)\n",
    "\n",
    "# requires GitHub LFS as the resulting pickle object is larger than 100MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this code to open the \n",
    "#with open(\"all_spacy_docs.pickle\", \"rb\") as f:\n",
    "#    loaded_all_docs = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIPELINE PART 2: Parts-of-Speech Filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6620"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keeping only Propernouns and Nouns\n",
    "\n",
    "filtered_docs_all = list([[token.text for token in doc if token.pos_ in ['PROPN', 'NOUN']] for doc in docs_all])\n",
    "len(filtered_docs_all)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIPELINE PART 3: Dictionary Filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Dictionaries for eachskill\n",
    "\n",
    "#Filtering for IT Skills: Microsoft\n",
    "MS_keys = [\"Microsoft\",\"MS\",\"MS-Office\",\"Powerpoint\",\"Excel\"]\n",
    "MS_score_cutoff = 80\n",
    "\n",
    "#Filtering for Financial Modelling \n",
    "# assumption: occurence of 'modelling' string is in the context of 'financial modelling'\n",
    "FM_keys = [\"modelling\"]\n",
    "FM_score_cutoff = 80\n",
    "\n",
    "#Filtering for Data Platform Skills: Bloomberg and/or FactSet\n",
    "DATA_keys = [\"Bloomberg\",\"FactSet\"]\n",
    "DATA_score_cutoff = 75\n",
    "\n",
    "# Programming: Python\n",
    "PY_keys = [\"Python\"]\n",
    "PY_score_cutoff = 75\n",
    "\n",
    "# Programming: Databases\n",
    "SQL_keys = [\"SQL\",\"mySQL\"]\n",
    "SQL_score_cutoff = 75\n",
    "\n",
    "# Programming: R\n",
    "R_keys = [\"RStudio\", \"R\"]\n",
    "R_score_cutoff = 80\n",
    "\n",
    "# Programming: etc.\n",
    "# assumption for category: these programming languages occur less than Python, R, SQL, etc.\n",
    "\n",
    "PETC_keys = [\"C++\",\"C#\",\"JAVA\",\"JavaScript\",\"CSS\",\"HTML\",\"PERL\"]\n",
    "PETC_score_cutoff = 90\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe for storing the keywords\n",
    "# these 2 dataframes will be the ones appended to by the functions/filters\n",
    "\n",
    "df_word = pd.DataFrame(columns=['Microsoft Office', 'Financial Modelling', 'Data Platform', 'Python', 'R', 'SQL','Other Programming Languages'])\n",
    "#df_word #for viewing\n",
    "\n",
    "# Dataframe for storing occurence of keywords\n",
    "\n",
    "df_bool = pd.DataFrame(columns=['Microsoft Office', 'Financial Modelling', 'Data Platform', 'Python', 'R', 'SQL','Other Programming Languages'])\n",
    "#df_bool # for viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to pass the texts through the filter and output the keywords extracted\n",
    "\n",
    "def dict_filter_word(input_text):\n",
    "    MS_match = [match for match in [process.extractOne(key, input_text, scorer = fuzz.token_set_ratio, score_cutoff = MS_score_cutoff) for key in MS_keys] if match is not None and match[1] >= MS_score_cutoff]\n",
    "    FM_match = [match for match in [process.extractOne(key, input_text, scorer = fuzz.token_set_ratio, score_cutoff = FM_score_cutoff) for key in FM_keys] if match is not None and match[1] >= FM_score_cutoff]\n",
    "    DATA_match = [match for match in [process.extractOne(key, input_text, scorer = fuzz.token_set_ratio, score_cutoff = DATA_score_cutoff) for key in DATA_keys] if match is not None and match[1] >= DATA_score_cutoff]\n",
    "    PY_match = [match for match in [process.extractOne(key, input_text, scorer = fuzz.token_set_ratio, score_cutoff = PY_score_cutoff) for key in PY_keys] if match is not None and match[1] >= PY_score_cutoff]\n",
    "    R_match = [match for match in [process.extractOne(key, input_text, scorer = fuzz.token_set_ratio, score_cutoff = R_score_cutoff) for key in R_keys] if match is not None and match[1] >= R_score_cutoff]\n",
    "    SQL_match = [match for match in [process.extractOne(key, input_text, scorer = fuzz.token_set_ratio, score_cutoff = SQL_score_cutoff) for key in SQL_keys] if match is not None and match[1] >= SQL_score_cutoff]\n",
    "    PETC_match = [match for match in [process.extractOne(key, input_text, scorer = fuzz.token_set_ratio, score_cutoff = PETC_score_cutoff) for key in PETC_keys] if match is not None and match[1] >= PETC_score_cutoff]\n",
    "\n",
    "    df_word.loc[len(df_word)] = [MS_match, FM_match, DATA_match, PY_match, R_match, SQL_match, PETC_match]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to pass the texts through the filter and output the occurence of keywords\n",
    "\n",
    "def dict_filter_bool(input_text):\n",
    "    MS = int(bool([match for match in [process.extractOne(key, input_text, scorer = fuzz.token_set_ratio, score_cutoff = MS_score_cutoff) for key in MS_keys] if match is not None and match[1] >= MS_score_cutoff]))\n",
    "    FM = int(bool([match for match in [process.extractOne(key, input_text, scorer = fuzz.token_set_ratio, score_cutoff = FM_score_cutoff) for key in FM_keys] if match is not None and match[1] >= FM_score_cutoff]))\n",
    "    DATA = int(bool([match for match in [process.extractOne(key, input_text, scorer = fuzz.token_set_ratio, score_cutoff = DATA_score_cutoff) for key in DATA_keys] if match is not None and match[1] >= DATA_score_cutoff]))\n",
    "    PY = int(bool([match for match in [process.extractOne(key, input_text, scorer = fuzz.token_set_ratio, score_cutoff = PY_score_cutoff) for key in PY_keys] if match is not None and match[1] >= PY_score_cutoff]))\n",
    "    R = int(bool([match for match in [process.extractOne(key, input_text, scorer = fuzz.token_set_ratio, score_cutoff = R_score_cutoff) for key in R_keys] if match is not None and match[1] >= R_score_cutoff]))\n",
    "    SQL = int(bool([match for match in [process.extractOne(key, input_text, scorer = fuzz.token_set_ratio, score_cutoff = SQL_score_cutoff) for key in SQL_keys] if match is not None and match[1] >= SQL_score_cutoff]))\n",
    "    PETC = int(bool([match for match in [process.extractOne(key, input_text, scorer = fuzz.token_set_ratio, score_cutoff = PETC_score_cutoff) for key in PETC_keys] if match is not None and match[1] >= PETC_score_cutoff]))\n",
    "\n",
    "    df_bool.loc[len(df_bool)] = [MS, FM, DATA, PY, R, SQL, PETC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6620"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the list containing the respective list of tokens for each jobs into a series \n",
    "filtered_docs_all_s = pd.Series(filtered_docs_all)\n",
    "len(filtered_docs_all_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/fuzzywuzzy/process.py\u001b[0m in \u001b[0;36mextractWithoutOrder\u001b[0;34m(query, choices, processor, scorer, score_cutoff)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# See if choices is a dictionary-like object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchoice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchoices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpre_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-eed6f8d27b76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#applying the filters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfiltered_docs_all_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_filter_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfiltered_docs_all_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_filter_bool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4356\u001b[0m         \"\"\"\n\u001b[0;32m-> 4357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4359\u001b[0m     def _reduce(\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1099\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m                     \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m                 )\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-4b8a7481ea4e>\u001b[0m in \u001b[0;36mdict_filter_word\u001b[0;34m(input_text)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mMS_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmatch\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractOne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuzz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_set_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_cutoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMS_score_cutoff\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMS_keys\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mMS_score_cutoff\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mFM_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmatch\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractOne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuzz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_set_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_cutoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFM_score_cutoff\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mFM_keys\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mFM_score_cutoff\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mDATA_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmatch\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractOne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuzz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_set_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_cutoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDATA_score_cutoff\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDATA_keys\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mDATA_score_cutoff\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mPY_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmatch\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractOne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuzz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_set_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_cutoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPY_score_cutoff\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mPY_keys\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mPY_score_cutoff\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mR_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmatch\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractOne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuzz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_set_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_cutoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR_score_cutoff\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mR_keys\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mR_score_cutoff\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-4b8a7481ea4e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mMS_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmatch\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractOne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuzz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_set_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_cutoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMS_score_cutoff\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMS_keys\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mMS_score_cutoff\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mFM_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmatch\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractOne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuzz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_set_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_cutoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFM_score_cutoff\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mFM_keys\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mFM_score_cutoff\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mDATA_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmatch\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractOne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuzz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_set_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_cutoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDATA_score_cutoff\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDATA_keys\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mDATA_score_cutoff\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mPY_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmatch\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractOne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuzz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_set_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_cutoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPY_score_cutoff\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mPY_keys\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mPY_score_cutoff\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mR_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmatch\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractOne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuzz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_set_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_cutoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR_score_cutoff\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mR_keys\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mR_score_cutoff\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/fuzzywuzzy/process.py\u001b[0m in \u001b[0;36mextractOne\u001b[0;34m(query, choices, processor, scorer, score_cutoff)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mbest_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractWithoutOrder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchoices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_cutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/fuzzywuzzy/process.py\u001b[0m in \u001b[0;36mextractWithoutOrder\u001b[0;34m(query, choices, processor, scorer, score_cutoff)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchoice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchoices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpre_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mscore_cutoff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/fuzzywuzzy/fuzz.py\u001b[0m in \u001b[0;36mtoken_set_ratio\u001b[0;34m(s1, s2, force_ascii, full_process)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtoken_set_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_ascii\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_process\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_token_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_ascii\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_ascii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_process\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_process\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/fuzzywuzzy/utils.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/fuzzywuzzy/fuzz.py\u001b[0m in \u001b[0;36m_token_set\u001b[0;34m(s1, s2, partial, force_ascii, full_process)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;31m# pull tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mtokens1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0mtokens2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mintersection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#applying the filters\n",
    "\n",
    "filtered_docs_all_s.apply(dict_filter_word)\n",
    "\n",
    "filtered_docs_all_s.apply(dict_filter_bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Group Audit\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is looking for an intern who can join the team as soon as possible. The group delivers services on behalf of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the Board of Managing Directors\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " as an independent, objective and risk-oriented assurance (audit) and consultant activity, which is designed to optimise the operations of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the Commerzbank Group\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " with regard to correctness, security and economic efficiency. The Group Audit London team mainly focuses on auditing the trading and sales business of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Commerzbank Corporates Clients\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", as well as advisory and structuring activities, and related \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Support and Risk Management\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " functions. The intern will be joining the team in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    London\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and assist the junior/senior auditors in carrying out internal audit testing across trading and sales business.Key activities:You will have the opportunity to join \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    one\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of our audit teams and support more experienced auditors. The learning curve will be steep as you move from \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    one\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " assignment to the next and will be exposed to a variety of products, processes and controls within the organisation. You’ll also meet other talented people from all over the world, enabling you to start building your own network. The role may involve travel.It is a unique opportunity to get a hands-on experience on the inner workings of a large organisation and a \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    first\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " step in a possible career in investment banking.Start: \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ASAPDuration\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ": \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    6 months\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " (with the possibility of extending to \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    12\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " months)Ideal candidate profile:Graduated in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the last 12 months\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " or working towards graduation towards Bachelors or \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Masters\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " degree in a numerical subject such as \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Finance\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Economics or Business\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " administration.Expected to or have achieved a minimum \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2:1\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    UK\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " Bachelors degree (or equivalent)Minimum \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    320 UCAS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " points (or \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    equivalent)Knowledge of Microsoft Office\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " (especially excel and word)Understanding of financial markets and keen interest in the sectorSome business knowledge or previous internships within \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Financial Services\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " but not essentialHighly motivated and results drivenExcellent analytical skills and able to deal confidently with peopleTeam playerStrong verbal and written communication skillsFluent \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    EnglishGerman\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " could be an advantage.</br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Individual Job View of NER \n",
    "# NER = Name Entity Recognition\n",
    "rend_doc_1 = docs_1[73]\n",
    "\n",
    "from spacy import displacy\n",
    "displacy.render(rend_doc_1,style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#Filtering for IT Skills: Microsoft\n",
    "MS_keys = [\"Microsoft\",\"MS\",\"MS-Office\",\"Powerpoint\",\"Excel\"]\n",
    "MS_score_cutoff = 75\n",
    "\n",
    "MS_match = [match for match in [process.extractOne(key, text, scorer = fuzz.token_set_ratio, score_cutoff = MS_score_cutoff) \n",
    "for key in MS_keys] if match is not None and match[1] >= MS_score_cutoff]\n",
    "\n",
    "print(MS_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('modelling', 100)]\n"
     ]
    }
   ],
   "source": [
    "#Filtering for Financial Modelling \n",
    "# assumption: occurence of 'modelling' string is in the context of 'financial modelling'\n",
    "FM_keys = [\"modelling\"]\n",
    "FM_score_cutoff = 75\n",
    "\n",
    "FM_match = [match for match in [process.extractOne(key, text, scorer = fuzz.token_set_ratio, score_cutoff = FM_score_cutoff)\n",
    "for key in FM_keys] if match is not None and match[1] >= FM_score_cutoff]\n",
    "\n",
    "print(FM_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#Filtering for Data Platform Skills: Bloomberg and/or FactSet\n",
    "DATA_keys = [\"Bloomberg\",\"FactSet\"]\n",
    "DATA_score_cutoff = 75\n",
    "\n",
    "DATA_match = [match for match in [process.extractOne(key, text, scorer = fuzz.token_set_ratio, score_cutoff = DATA_score_cutoff) \n",
    "for key in DATA_keys] if match is not None and match[1] >= DATA_score_cutoff]\n",
    "\n",
    "print(DATA_match)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering for Programming Skills: Python, SQL, Java, JavaScript, C++, C#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Python', 100)]\n"
     ]
    }
   ],
   "source": [
    "# Programming: Python\n",
    "PY_keys = [\"Python\"]\n",
    "PY_score_cutoff = 75\n",
    "\n",
    "PY_match = [match for match in [process.extractOne(key, text, scorer = fuzz.token_set_ratio, score_cutoff = PY_score_cutoff) \n",
    "for key in PY_keys] if match is not None and match[1] >= PY_score_cutoff]\n",
    "print(PY_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SQL', 100), ('SQL', 75)]\n"
     ]
    }
   ],
   "source": [
    "# Programming: Databases\n",
    "SQL_keys = [\"SQL\",\"mySQL\"]\n",
    "SQL_score_cutoff = 75\n",
    "\n",
    "SQL_match = [match for match in [process.extractOne(key, text, scorer = fuzz.token_set_ratio, score_cutoff = SQL_score_cutoff) \n",
    "for key in SQL_keys] if match is not None and match[1] >= SQL_score_cutoff]\n",
    "print(SQL_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('R', 100)]\n"
     ]
    }
   ],
   "source": [
    "# Programming: R\n",
    "R_keys = [\"RStudio\", \"R\"]\n",
    "R_score_cutoff = 75\n",
    "\n",
    "R_match = [match for match in [process.extractOne(key, text, scorer = fuzz.token_set_ratio, score_cutoff = R_score_cutoff) \n",
    "for key in R_keys] if match is not None and match[1] >= R_score_cutoff]\n",
    "print(R_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('C', 100), ('C', 100)]\n"
     ]
    }
   ],
   "source": [
    "PETC_keys = [\"C++\",\"C#\",\"JAVA\",\"JavaScript\",\"CSS\",\"HTML\",\"PERL\"]\n",
    "PETC_score_cutoff = 75\n",
    "\n",
    "PETC_match = [match for match in [process.extractOne(key, text, scorer = fuzz.token_set_ratio, score_cutoff = PETC_score_cutoff) for key in PETC_keys] if match is not None and match[1] >= PETC_score_cutoff]\n",
    "print(PETC_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to pass the texts through the filter and output the keywords extracted\n",
    "\n",
    "def dict_filter_word(input_text):\n",
    "    MS_match = [match for match in [process.extractOne(key, input_text, scorer = fuzz.token_set_ratio, score_cutoff = MS_score_cutoff) for key in MS_keys] if match is not None and match[1] >= MS_score_cutoff]\n",
    "    FM_match = [match for match in [process.extractOne(key, input_text, scorer = fuzz.token_set_ratio, score_cutoff = FM_score_cutoff) for key in FM_keys] if match is not None and match[1] >= FM_score_cutoff]\n",
    "    DATA_match = [match for match in [process.extractOne(key, input_text, scorer = fuzz.token_set_ratio, score_cutoff = DATA_score_cutoff) for key in DATA_keys] if match is not None and match[1] >= DATA_score_cutoff]\n",
    "    PY_match = [match for match in [process.extractOne(key, input_text, scorer = fuzz.token_set_ratio, score_cutoff = PY_score_cutoff) for key in PY_keys] if match is not None and match[1] >= PY_score_cutoff]\n",
    "    R_match = [match for match in [process.extractOne(key, input_text, scorer = fuzz.token_set_ratio, score_cutoff = R_score_cutoff) for key in R_keys] if match is not None and match[1] >= R_score_cutoff]\n",
    "    SQL_match = [match for match in [process.extractOne(key, input_text, scorer = fuzz.token_set_ratio, score_cutoff = SQL_score_cutoff) for key in SQL_keys] if match is not None and match[1] >= SQL_score_cutoff]\n",
    "    PETC_match = [match for match in [process.extractOne(key, input_text, scorer = fuzz.token_set_ratio, score_cutoff = PETC_score_cutoff) for key in PETC_keys] if match is not None and match[1] >= PETC_score_cutoff]\n",
    "\n",
    "    df_word.loc[len(df_word)] = [MS_match, FM_match, DATA_match, PY_match, R_match, SQL_match, PETC_match]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to pass the texts through the filter and output the occurence of keywords\n",
    "\n",
    "def dict_filter_bool(input_text):\n",
    "    MS = int(bool([match for match in [process.extractOne(key, input_text, scorer = fuzz.token_set_ratio, score_cutoff = MS_score_cutoff) for key in MS_keys] if match is not None and match[1] >= MS_score_cutoff]))\n",
    "    FM = int(bool([match for match in [process.extractOne(key, input_text, scorer = fuzz.token_set_ratio, score_cutoff = FM_score_cutoff) for key in FM_keys] if match is not None and match[1] >= FM_score_cutoff]))\n",
    "    DATA = int(bool([match for match in [process.extractOne(key, input_text, scorer = fuzz.token_set_ratio, score_cutoff = DATA_score_cutoff) for key in DATA_keys] if match is not None and match[1] >= DATA_score_cutoff]))\n",
    "    PY = int(bool([match for match in [process.extractOne(key, input_text, scorer = fuzz.token_set_ratio, score_cutoff = PY_score_cutoff) for key in PY_keys] if match is not None and match[1] >= PY_score_cutoff]))\n",
    "    R = int(bool([match for match in [process.extractOne(key, input_text, scorer = fuzz.token_set_ratio, score_cutoff = R_score_cutoff) for key in R_keys] if match is not None and match[1] >= R_score_cutoff]))\n",
    "    SQL = int(bool([match for match in [process.extractOne(key, input_text, scorer = fuzz.token_set_ratio, score_cutoff = SQL_score_cutoff) for key in SQL_keys] if match is not None and match[1] >= SQL_score_cutoff]))\n",
    "    PETC = int(bool([match for match in [process.extractOne(key, input_text, scorer = fuzz.token_set_ratio, score_cutoff = PETC_score_cutoff) for key in PETC_keys] if match is not None and match[1] >= PETC_score_cutoff]))\n",
    "\n",
    "    df_bool.loc[len(df_bool)] = [MS, FM, DATA, PY, R, SQL, PETC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_txts_s = filtered_docs_all[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Microsoft</th>\n",
       "      <th>Financial Modelling</th>\n",
       "      <th>Data Platform</th>\n",
       "      <th>Python</th>\n",
       "      <th>R</th>\n",
       "      <th>SQL</th>\n",
       "      <th>Other Programming Languages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Microsoft Financial Modelling Data Platform Python  R SQL  \\\n",
       "0         1                   0             0      0  0   0   \n",
       "1         0                   0             0      0  0   0   \n",
       "2         0                   0             0      0  0   0   \n",
       "3         1                   0             0      0  0   0   \n",
       "4         1                   0             0      0  0   0   \n",
       "5         1                   1             0      0  0   0   \n",
       "6         1                   1             0      0  0   0   \n",
       "7         1                   1             0      0  0   0   \n",
       "8         1                   0             0      0  0   0   \n",
       "9         1                   0             0      0  0   0   \n",
       "\n",
       "  Other Programming Languages  \n",
       "0                           1  \n",
       "1                           0  \n",
       "2                           0  \n",
       "3                           1  \n",
       "4                           0  \n",
       "5                           0  \n",
       "6                           0  \n",
       "7                           0  \n",
       "8                           0  \n",
       "9                           1  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_txts_s = pd.Series(tst_txts)\n",
    "tst_txts_s.apply(dict_filter_bool)\n",
    "df_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Microsoft</th>\n",
       "      <th>Financial Modelling</th>\n",
       "      <th>Data Platform</th>\n",
       "      <th>Python</th>\n",
       "      <th>R</th>\n",
       "      <th>SQL</th>\n",
       "      <th>Other Programming Languages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(Microsoft, 100), (Office, 100), (PowerPoint,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(c., 100), (c., 100)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(MS, 100), (MS, 100), (PowerPoint, 100), (Exc...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(class, 75)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(Office, 100), (PowerPoint, 100), (Excel, 100)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[(Excel, 100)]</td>\n",
       "      <td>[(modeling, 94)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[(Excel, 100)]</td>\n",
       "      <td>[(modeling, 94)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[(Microsoft, 100), (office, 100), (PowerPoint,...</td>\n",
       "      <td>[(modelling, 100)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[(office, 100)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[(offices, 75)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(Class, 75)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Microsoft Financial Modelling  \\\n",
       "0  [(Microsoft, 100), (Office, 100), (PowerPoint,...                  []   \n",
       "1                                                 []                  []   \n",
       "2                                                 []                  []   \n",
       "3  [(MS, 100), (MS, 100), (PowerPoint, 100), (Exc...                  []   \n",
       "4   [(Office, 100), (PowerPoint, 100), (Excel, 100)]                  []   \n",
       "5                                     [(Excel, 100)]    [(modeling, 94)]   \n",
       "6                                     [(Excel, 100)]    [(modeling, 94)]   \n",
       "7  [(Microsoft, 100), (office, 100), (PowerPoint,...  [(modelling, 100)]   \n",
       "8                                    [(office, 100)]                  []   \n",
       "9                                    [(offices, 75)]                  []   \n",
       "\n",
       "  Data Platform Python   R SQL Other Programming Languages  \n",
       "0            []     []  []  []      [(c., 100), (c., 100)]  \n",
       "1            []     []  []  []                          []  \n",
       "2            []     []  []  []                          []  \n",
       "3            []     []  []  []               [(class, 75)]  \n",
       "4            []     []  []  []                          []  \n",
       "5            []     []  []  []                          []  \n",
       "6            []     []  []  []                          []  \n",
       "7            []     []  []  []                          []  \n",
       "8            []     []  []  []                          []  \n",
       "9            []     []  []  []               [(Class, 75)]  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_txts_s.apply(dict_filter_word)\n",
    "df_word"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code for applying the pipeline to the entire dataset\n",
    "\n",
    "1. Cleaning the data \n",
    "-identify index of non-text data\n",
    "-removing nan (non-text) data\n",
    "\n",
    "2. Convert to nlp object 'document'\n",
    "\n",
    "\n",
    "3. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running Code on the Entire Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convering the column of texts into a list of text\n",
    "lst_lst = df_text.values.tolist()\n",
    "len(lst_lst)\n",
    "\n",
    "# storing the data type of every element in the list of texts (which contains all of the job details)\n",
    "# we expect the text data to be a 'str' object\n",
    "# non_str_index tells us which indexes include non-string values and therefore should be removed\n",
    "non_str_index = [i for i, sublst in enumerate(lst_lst) if any(not isinstance(val, str) for val in sublst)]\n",
    "non_str_index\n",
    "\n",
    "len(df_text) # NEW CHUNK\n",
    "\n",
    "df_text_filtered = df_text.drop(non_str_index, axis=0, inplace=False) # NEW CHUNK\n",
    "len(df_text_filtered)\n",
    "\n",
    "df_text_all = df_text_filtered  # NEW CHUNK\n",
    "len(df_text_all)\n",
    "\n",
    "\n",
    "# use this to apply the nlp() to the entire dataset\n",
    "\n",
    "all_docs = df_text_all['details'].apply(nlp)\n",
    "len(all_docs) \n",
    "\n",
    "\n",
    " # NEW CHUNK\n",
    "\n",
    "# Optional!\n",
    "\n",
    "# use this to store the list of documents locally (running nlp() again takes time)\n",
    "\n",
    "#with open(\"all_spacy_docs.pickle\", \"wb\") as f:\n",
    "#    pickle.dump(all_docs, f)\n",
    "\n",
    "# requires GitHub LFS as the resulting pickle object is larger than 100MB\n",
    "\n",
    "# NEW CHUNK\n",
    "\n",
    "# use this code to open the \n",
    "#with open(\"all_spacy_docs.pickle\", \"rb\") as f:\n",
    "#    loaded_all_docs = pickle.load(f)\n",
    "\n",
    "\n",
    "# NEW CHUNK\n",
    "\n",
    "# Keeping only Propernouns and Nouns\n",
    "\n",
    "filtered_docs_all = list([[token.text for token in doc if token.pos_ in ['PROPN', 'NOUN']] for doc in all_docs])\n",
    "len(filtered_docs_all)\n",
    "\n",
    "# NEW CHUNK\n",
    "\n",
    "filtered_docs_all_s = pd.Series(filtered_docs_all)\n",
    "len(filtered_docs_all_s)\n",
    "\n",
    "# NEW CHUNK\n",
    "\n",
    "all_words = filtered_docs_all_s.apply(dict_filter_word)\n",
    "len(all_words)\n",
    "\n",
    "# NEW CHUNK\n",
    "\n",
    "all_bools = filtered_docs_all_s.apply(dict_filter_bool)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "END of PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREATING DATAFRAME FOR R\n",
    "\n",
    "# 1 Turning titles \n",
    "df_title_r_1 = df_title[0:101]\n",
    "df_title_r_1 = pd.DataFrame(df_title_r_1)\n",
    "type(df_title_r_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rothschild &amp; Co - Private Equity Long-Term Int...</td>\n",
       "      <td>London month internship exciting opportunity R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023 HSBC Global Graduate Programme (Hong Kong...</td>\n",
       "      <td>excited career many paths possibilities global...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023 HSBC Global Internship Programme (Hong Ko...</td>\n",
       "      <td>excited career many paths possibilities global...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Graduate Training Scheme, Capital Markets</td>\n",
       "      <td>Graduate Training Scheme LondonGreySpark Partn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6-Months Internship – Sell-side Tech M&amp;A</td>\n",
       "      <td>IPTP software decades deep experience technolo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>M&amp;A Analyst Intern</td>\n",
       "      <td>MAJOR RESPONSIBILITIESGather financial operat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>12 Month Internship - Financial Crimes and San...</td>\n",
       "      <td>Job summaryFinancial Crime Financial Security ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Investment Associate - Fixed Income</td>\n",
       "      <td>Position OverviewPutnam energetic curious indi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>12 Month Internship - Central Compliance</td>\n",
       "      <td>SummaryThe Central Compliance team responsible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>12 Month Internship - Market Activity Monitoring</td>\n",
       "      <td>Key ResponsibilitiesThis role MAM Section Head...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    Rothschild & Co - Private Equity Long-Term Int...   \n",
       "1    2023 HSBC Global Graduate Programme (Hong Kong...   \n",
       "2    2023 HSBC Global Internship Programme (Hong Ko...   \n",
       "3           Graduate Training Scheme, Capital Markets    \n",
       "4             6-Months Internship – Sell-side Tech M&A   \n",
       "..                                                 ...   \n",
       "96                                M&A Analyst Intern     \n",
       "97   12 Month Internship - Financial Crimes and San...   \n",
       "98                 Investment Associate - Fixed Income   \n",
       "99            12 Month Internship - Central Compliance   \n",
       "100   12 Month Internship - Market Activity Monitoring   \n",
       "\n",
       "                                                     0  \n",
       "0    London month internship exciting opportunity R...  \n",
       "1    excited career many paths possibilities global...  \n",
       "2    excited career many paths possibilities global...  \n",
       "3    Graduate Training Scheme LondonGreySpark Partn...  \n",
       "4    IPTP software decades deep experience technolo...  \n",
       "..                                                 ...  \n",
       "96   MAJOR RESPONSIBILITIESGather financial operat...  \n",
       "97   Job summaryFinancial Crime Financial Security ...  \n",
       "98   Position OverviewPutnam energetic curious indi...  \n",
       "99   SummaryThe Central Compliance team responsible...  \n",
       "100  Key ResponsibilitiesThis role MAM Section Head...  \n",
       "\n",
       "[101 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREATING DATAFRAME FOR R\n",
    "\n",
    "df_r_1 = pd.concat([df_title_r_1, df_fil_1], axis = 1)\n",
    "df_r_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2R Capital Investment Management Limited independent investment company London UK successful credit business process new initiatives equity investing private assets equity primary objective long term capital clients commensurate reasonable risk attention mid - sized European companies fundamental investors extensive research businesses regions industry sectors significant expertise private assets space equity debt small medium sized companies significant growth potential sectors regions Job Opportunities analysts investment opportunities Europe internship full time positions available Targeted training successful candidates self starters activities little supervision keen interest securities investing good research writing financial modelling abilities European languages important Day day activities search origination potential investment opportunities primary research analysis specific sectors companies valuation investment opportunities Direct interaction entrepreneurs managers investors possible unique opportunity new investment team direct exposure portfolio manager integral part investment decision process'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r_1.iloc[95,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export as .csv file\n",
    "#df_r_1.to_csv('df_r_1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
